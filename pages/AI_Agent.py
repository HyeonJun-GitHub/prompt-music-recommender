import os
import base64
import requests
import json
import re
import streamlit as st
import openai
import httpx
from bs4 import BeautifulSoup
from datetime import datetime

# ChatBot í´ë˜ìŠ¤ ì •ì˜
class ChatBot:
    def __init__(self, system=""):
        self.system = system
        self.messages = []
        if self.system:
            self.messages.append({"role": "system", "content": system})

    def __call__(self, message):
        self.messages.append({"role": "user", "content": message})
        result = self.execute()
        self.messages.append({"role": "assistant", "content": result})
        return result

    def execute(self):
        try:
            completion = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=self.messages
            )
            # ë°˜í™˜ ë°ì´í„° ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
            choices = completion.get("choices", [])
            if choices:
                return choices[0].get("message", {}).get("content", "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                return "OpenAI ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
        except openai.error.OpenAIError as e:
            return f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# íˆìŠ¤í† ë¦¬ ì €ì¥ ë° ê²€ìƒ‰
history = []

def save_to_history(data):
    """íˆìŠ¤í† ë¦¬ì— ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    history.append(data)

def search_history(query):
    """íˆìŠ¤í† ë¦¬ì—ì„œ ì¿¼ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    for item in history:
        if item.get("query") == query:
            return item.get("response")
    return None

# Action ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
def namu_wiki(query):
    base_url = f"https://namu.wiki/w/{query}"

    try:
        # ë‚˜ë¬´ìœ„í‚¤ í˜ì´ì§€ ìš”ì²­
        response = httpx.get(base_url)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ

        # BeautifulSoupì„ ì‚¬ìš©í•˜ì—¬ HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')

        # ë‚˜ë¬´ìœ„í‚¤ì—ì„œ ìš”ì•½ ì •ë³´ ì¶”ì¶œ
        # ì£¼ë¡œ ë¬¸ì„œì˜ ì²« ë²ˆì§¸ ë‹¨ë½(ìš”ì•½) ì •ë³´ë¥¼ ê°€ì ¸ì˜´
        content_div = soup.find('div', {'class': 'wiki-paragraph'})
        
        if not content_div:
            return f"'{query}'ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # ì²« ë²ˆì§¸ ë‹¨ë½ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        summary = content_div.get_text(strip=True)  # ìˆ˜ì •: .get_text() ì‚¬ìš©
        return summary

    except httpx.RequestError as e:
        return f"HTTP ìš”ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    except Exception as e:
        return f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def extract_date(text):
    date_patterns = [
        r"(\d{4}[-/.]\d{1,2}[-/.]\d{1,2})",  # YYYY-MM-DD
        r"(\d{1,2}ì›” \d{1,2}ì¼)",             # MMì›” DDì¼
        r"(\d{4}ë…„ \d{1,2}ì›” \d{1,2}ì¼)"      # YYYYë…„ MMì›” DDì¼
    ]
    for pattern in date_patterns:
        match = re.search(pattern, text)
        if match:
            return match.group(0)
    return None

def select_most_recent(results):
    if not isinstance(results, list):
        return None  # ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ

    recent_date = None
    recent_result = None

    for result in results:
        # ê²°ê³¼ê°€ ë”•ì…”ë„ˆë¦¬ì¸ì§€ í™•ì¸
        if not isinstance(result, dict) or "snippet" not in result:
            continue

        date_text = extract_date(result["snippet"])  # ê²°ê³¼ì˜ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
        if date_text:
            try:
                date_obj = datetime.strptime(date_text, "%Y-%m-%d")
                if not recent_date or date_obj > recent_date:
                    recent_date = date_obj
                    recent_result = result
            except ValueError:
                pass  # ë‚ ì§œ í˜•ì‹ì´ ë§ì§€ ì•Šìœ¼ë©´ ë¬´ì‹œ
    return recent_result

def web_search(query, source="google"):
    if source == "google":
        url = "https://www.google.com/search"
        params = {"q": query}
    elif source == "youtube":
        url = "https://www.youtube.com/results"
        params = {"search_query": query}
    elif source == "naver":
        url = "https://search.naver.com/search.naver"
        params = {"query": query}
    else:
        st.text(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ì…ë‹ˆë‹¤: {source}")
        return f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ì…ë‹ˆë‹¤: {source}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        st.text(f"ì›¹ ìš”ì²­ ì‹¤í–‰: {url}, params={params}")
        response = httpx.get(url, params=params, headers=headers)
        response.raise_for_status()
        st.text(f"ìš”ì²­ ì„±ê³µ: {response.status_code}, URL: {response.url}")

        # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
        soup = BeautifulSoup(response.text, 'html.parser')

        # ê° ì†ŒìŠ¤ì— ë§ëŠ” ë°ì´í„° ì¶”ì¶œ ë°©ì‹ ì ìš©
        if source == "google":
            links = re.findall(r'<a href="(https://www.google.com/url\?q=[^"]+)', response.text)
            parsed_links = [re.sub(r'https://www.google.com/url\?q=|&.*', '', link) for link in links[:5]]
            st.text(f"Google ë§í¬ ê²°ê³¼: {parsed_links}")
            return parsed_links

        elif source == "youtube":
            video_links = soup.find_all("a", href=True)
            filtered_links = [f"https://www.youtube.com{link['href']}" for link in video_links if "/watch?" in link["href"]]
            st.text(f"YouTube ë§í¬ ê²°ê³¼: {filtered_links}")
            return filtered_links[:5]

        elif source == "naver":
            summaries = soup.find_all('div', {'class': 'api_txt_lines'})
            parsed_summaries = [summary.get_text(strip=True) for summary in summaries[:5]]
            st.text(f"Naver ìš”ì•½ ê²°ê³¼: {parsed_summaries}")
            return parsed_summaries

        else:
            st.text("ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ì…ë‹ˆë‹¤.")
            return "ì•Œ ìˆ˜ ì—†ëŠ” ì†ŒìŠ¤ì…ë‹ˆë‹¤."

    except httpx.RequestError as re:
        st.error(f"HTTP ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {re}")
        return f"HTTP ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(re)}"
    except Exception as e:
        st.error(f"ì›¹ ê²€ìƒ‰ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def multi_web_search_with_date(query):
    sources = ["google", "youtube", "naver"]
    all_results = {}

    for source in sources:
        st.text(f"ì†ŒìŠ¤ '{source}'ì— ëŒ€í•´ ê²€ìƒ‰ ì‹œì‘: {query}")
        search_result = web_search(query, source=source)
        
        # ë°˜í™˜ ê°’ ë””ë²„ê¹…
        st.text(f"'{source}' ê²€ìƒ‰ ê²°ê³¼: {search_result}")

        if isinstance(search_result, str):
            st.text(f"'{source}' ê²°ê³¼ê°€ ë¬¸ìì—´ í˜•ì‹: {search_result}")
            try:
                search_result = json.loads(search_result)
            except json.JSONDecodeError:
                st.text(f"'{source}' ê²°ê³¼ê°€ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
                search_result = None

        if isinstance(search_result, list):
            st.text(f"'{source}' ê²°ê³¼ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹. ë‚ ì§œ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ìµœì‹  ë°ì´í„° ì„ íƒ ì¤‘...")
            recent_result = select_most_recent(search_result)
            st.text(f"'{source}' ìµœì‹  ë°ì´í„°: {recent_result}")
            all_results[source] = recent_result
        else:
            st.text(f"'{source}' ê²°ê³¼ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì²˜ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            all_results[source] = search_result  # ì›ë³¸ ì €ì¥ (None í¬í•¨ ê°€ëŠ¥)

    # ê²°ê³¼ ë°˜í™˜
    combined_results = []
    for source, result in all_results.items():
        if result:
            combined_results.append(f"**{source.capitalize()}**: {result}")
            st.text(f"ìµœì¢… ê²°ê³¼ ì¶”ê°€: {result}")
        else:
            st.text(f"'{source}'ì—ì„œ ê²°ê³¼ ì—†ìŒ.")

    return "\n".join(combined_results)


# ì•„í‹°ìŠ¤íŠ¸ ê²€ìƒ‰ API í˜¸ì¶œ í•¨ìˆ˜
def search_api(query):
    url = f"http://app.genie.co.kr/search/main/search.json?query={query}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148"
    }
    
    try:
        # API í˜¸ì¶œ ì‹œ í—¤ë” ì¶”ê°€
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # HTTP ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì˜ˆì™¸ ë°œìƒ
        
        try:
            data = response.json()  # JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì‹œë„
        except ValueError:
            st.error("API ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì‘ë‹µ ë‚´ìš©: " + response.text)
            return [], []
        
        # ê³¡ ì´ë¦„ê³¼ ID ì¶”ì¶œ
        song_list = [
            {
                "name": f"{song["song_name"].get("original", "Unknown Song")} - {song["artist_name"].get("original", "Unknown Song"),}",
                "id": song.get("song_id", None)
            }
            for song in data.get('searchResult', {}).get('result', {}).get('songs', {}).get('items', [])
        ]
        
        # ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ê³¼ ID ì¶”ì¶œ
        artist_list = [
            {
                "name": artist["artist_name"].get("original", "Unknown Artist"),
                "id": artist.get("artist_id", None)
            }
            for artist in data.get('searchResult', {}).get('result', {}).get('artists', {}).get('items', [])
        ]
        
        result = {
            "song": song_list if song_list else "null",
            "artist": artist_list if artist_list else "null"
        }
        
        # JSON ë¬¸ìì—´ë¡œ ë°˜í™˜
        return json.dumps(result, ensure_ascii=False, indent=2)

    except requests.exceptions.RequestException as e:
        return json.dumps({"song": "null", "artist": "null"}, ensure_ascii=False)

    # except requests.exceptions.RequestException as e:
    #     st.error(f"API ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    #     return [], []

def analyze_data(query):
    """ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê±°ë‚˜ íˆìŠ¤í† ë¦¬ì—ì„œ ê²€ìƒ‰"""
    cached_response = search_history(query)
    if cached_response:
        return cached_response
    return "No cached data. Please run a search first."

known_actions = {
    "namu_wiki": namu_wiki,
    "multi_web_search_with_date": multi_web_search_with_date,
    "search_api": search_api,
    "save_to_history": save_to_history,
    "search_history": search_history,
    "analyze_data": analyze_data,
}

action_re = re.compile(r'^Action: (\w+): (.*)')

# ì‚¬ì´ë“œë°”ì—ì„œ OpenAI API í‚¤ ì…ë ¥
with st.sidebar:
    openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
    openai.api_key = openai_api_key
    os.environ["OPENAI_API_KEY"] = openai_api_key

# ë°°ê²½ ì´ë¯¸ì§€ ì„¤ì • (ì˜µì…˜)
background_img_path = os.path.join(os.getcwd(), "background.jpg")
if os.path.exists(background_img_path):
    with open(background_img_path, "rb") as img_file:
        background_img_base64 = base64.b64encode(img_file.read()).decode()
    st.markdown(
        f"""
        <style>
        .stApp {{
            background-image: url("data:image/jpg;base64,{background_img_base64}");
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
        }}
        </style>
        """,
        unsafe_allow_html=True
    )

# CSS ìŠ¤íƒ€ì¼ ì •ì˜
st.markdown(
    """
    <style>
    .chat-container {
        display: flex;
        flex-direction: column;
        gap: 10px;
    }
    .chat-bubble {
        padding: 10px 15px;
        margin: 10px 0;
        font-size: 16px;
        word-wrap: break-word;
        display: inline-block;
        max-width: 80%; /* ë§í’ì„ ì˜ ìµœëŒ€ ë„ˆë¹„ë¥¼ 80%ë¡œ ì œí•œ */
    }
    .user-message {
        background-color: #ffffff; /*#D3D3D3;*/
        color: black;
        text-align: left; /* ë§í’ì„  ë‚´ë¶€ í…ìŠ¤íŠ¸ëŠ” ì™¼ìª½ ì •ë ¬ */
        float: right; /* ë§í’ì„ ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì •ë ¬ */
        clear: both; /* ë§í’ì„  ì‚¬ì´ ê°„ê²© ë³´ì¥ */
        border: 2px solid #ccc;
        border-radius: 15px;
        border-top-right-radius: 0px;
    }
    .ai-message {
        background-color: #3e95f8;
        color: white;
        text-align: left; /* ë§í’ì„  ë‚´ë¶€ í…ìŠ¤íŠ¸ëŠ” ì™¼ìª½ ì •ë ¬ */
        float: left; /* ë§í’ì„ ì„ ì™¼ìª½ìœ¼ë¡œ ì •ë ¬ */
        clear: both; /* ë§í’ì„  ì‚¬ì´ ê°„ê²© ë³´ì¥ */
        border: 2px solid #ccc;
        border-radius: 15px;
        border-top-left-radius: 0px;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "Genie ğŸ¤– : ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
if "past" not in st.session_state:
    st.session_state.past = []
if "generated" not in st.session_state:
    st.session_state.generated = []

# ChatBot ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
bot_prompt = """
You run in a loop of Thought, Action, PAUSE, Observation.
At the end of the loop, you output an Answer.
Use Thought to describe your thoughts about the question you have been asked.
Use Action to run one of the actions available to you - then return PAUSE.
Observation will be the result of running those actions.

----------------------------------------------------

**Important:** Always provide the final Answer in Korean, regardless of the input language.

----------------------------------------------------

Available Actions:
1. namu_wiki:
e.g. namu_wiki: ì„±ì‹œê²½ - ê±°ë¦¬ì—ì„œ
Returns a summary from searching namu_wiki.

2. multi_web_search_with_date:
e.g. multi_web_search_with_date: ë‹¤ë¹„ì¹˜ ìµœê·¼ ë°©ì†¡
Searches for the most recent information about the given query from multiple sources (Google, YouTube, Naver).
Returns a summary of the most recent and relevant information from all sources, sorted by date.

3. search_api:
e.g. search_api: ì„±ì‹œê²½ - ê±°ë¦¬ì—ì„œ
Search Simon's blog for information about both artists and song titles. If the name or title is in Korean, use the Korean characters.

4. save_to_history:
e.g. save_to_history: { "query": "ì„±ì‹œê²½ - ê±°ë¦¬ì—ì„œ", "response": "ì„±ì‹œê²½ì€ ëŒ€í•œë¯¼êµ­ì˜ ë°œë¼ë“œ ê°€ìˆ˜ë¡œ, 'ê±°ë¦¬ì—ì„œ'ëŠ” ì´ë³„ì˜ ìŠ¬í””ì„ ë‹¤ë£¬ ê·¸ì˜ ëŒ€í‘œê³¡ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤." }
Saves a query and its corresponding response into the history.

5. search_history:
e.g. search_history: "ì„±ì‹œê²½ - ê±°ë¦¬ì—ì„œ"
Searches the history for a query and returns the saved response, if available.

6. analyze_data:
e.g. analyze_data: { "query": "Playlists with over 10,000 views" }
Analyzes data by either searching the history for a matching query or performing new computations based on the dataset structure provided below.

----------------------------------------------------

**History Management**:
- Every query and its result are stored using the `save_to_history` action.
- The `search_history` action retrieves a previously saved response based on a matching query.
- `analyze_data` automatically checks the history using `search_history` before performing new computations.

----------------------------------------------------

**`search_api(json format)` Dataset Structure**:
The dataset contains the following variables:

1. ì „ì²´ ë°ì´í„° ê´€ë ¨ ë³€ìˆ˜:
- `total`: ë°ì´í„°ì˜ ì´ ê°œìˆ˜ì…ë‹ˆë‹¤. (ì˜ˆ: ì „ì²´ ë°ì´í„°ê°€ 120ê°œì¸ ê²½ìš° `total: 120`).
- `size`: ë°ì´í„°ì˜ í¬ê¸°ì…ë‹ˆë‹¤. ë‹¨ìœ„ëŠ” MB ë˜ëŠ” KBì…ë‹ˆë‹¤. (ì˜ˆ: `size: 10.5`ëŠ” 10.5MB).
- `items`: ì„¸ë¶€ í•­ëª©ì˜ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ê° í•­ëª©ì€ ì•„ë˜ ë³€ìˆ˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

2. ê³µí†µ ë³€ìˆ˜:
- `artist_name`: ì•„í‹°ìŠ¤íŠ¸ ì´ë¦„ì…ë‹ˆë‹¤. (ì˜ˆ: `"BTS"`).
- `song_name`: ê³¡ ì´ë¦„ì…ë‹ˆë‹¤. (ì˜ˆ: `"Dynamite"`).
- `album_name`: ì•¨ë²” ì´ë¦„ì…ë‹ˆë‹¤. (ì˜ˆ: `"BE"`).
- `tag`: ê³¡ ë˜ëŠ” í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ íƒœê·¸ì…ë‹ˆë‹¤. (ì˜ˆ: `"pop, dance, hit"`).
- `category`: ë°ì´í„°ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. (ì˜ˆ: `"trending"` ë˜ëŠ” `"user-generated"`).
- `disp_dt`: ë°ì´í„°ê°€ ë°°í¬ë˜ê±°ë‚˜ í‘œì‹œëœ ë‚ ì§œì…ë‹ˆë‹¤. (ì˜ˆ: `"2024-12-01"`).
- `reg_dt`: ë°ì´í„°ê°€ ë“±ë¡ëœ ë‚ ì§œì…ë‹ˆë‹¤. (ì˜ˆ: `"2024-11-28"`).

3. íŠ¹ì • ë°ì´í„° ì¹´í…Œê³ ë¦¬ ê´€ë ¨ ë³€ìˆ˜:
- Playlist:
  - `title`: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì œëª©ì…ë‹ˆë‹¤. (ì˜ˆ: `"Morning Vibes"`).
  - `contents`: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì„¤ëª…ì…ë‹ˆë‹¤. (ì˜ˆ: `"A collection of upbeat songs to start your day."`).
  - `img_path`: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ê°€ë¦¬í‚¤ëŠ” ê²½ë¡œì…ë‹ˆë‹¤. (ì˜ˆ: `"https://example.com/images/morning_vibes.jpg"`).
  - `song`: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— í¬í•¨ëœ ê³¡ì˜ ê°œìˆ˜ì…ë‹ˆë‹¤. (ì˜ˆ: `25`).
  - `view`: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¡°íšŒìˆ˜ì…ë‹ˆë‹¤. (ì˜ˆ: `100000`).
  - `favorite`: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¦ê²¨ì°¾ê¸° íšŸìˆ˜ì…ë‹ˆë‹¤. (ì˜ˆ: `5000`).
  - `popular_all`: ì „ì²´ ê¸°ê°„ ë™ì•ˆì˜ ì¸ê¸° ìˆœìœ„ì…ë‹ˆë‹¤. (ì˜ˆ: `1`).
  - `popular_recent`: ìµœê·¼ ê¸°ê°„ ë™ì•ˆì˜ ì¸ê¸° ìˆœìœ„ì…ë‹ˆë‹¤. (ì˜ˆ: `3`).

- Lyrics:
  - `lyrics`: ê³¡ì˜ ê°€ì‚¬ì…ë‹ˆë‹¤. (ì˜ˆ: `"Oh, oh, I'm in love with you."`).
  - `file_path`: ê°€ì‚¬ íŒŒì¼ ê²½ë¡œì…ë‹ˆë‹¤. (ì˜ˆ: `"/lyrics/BTS_Dynamite.txt"`).
  - `file_size`: ê°€ì‚¬ íŒŒì¼ í¬ê¸°ì…ë‹ˆë‹¤. ë‹¨ìœ„ëŠ” KB ë˜ëŠ” MBì…ë‹ˆë‹¤. (ì˜ˆ: `"1.2 KB"`).

- Songs:
  - `image_path`: ê³¡ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ ê²½ë¡œì…ë‹ˆë‹¤. (ì˜ˆ: `"https://example.com/images/dynamite.jpg"`).
  - `misspellings`: ê³¡ ì´ë¦„ê³¼ ê´€ë ¨ëœ ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤íƒ€ ëª©ë¡ì…ë‹ˆë‹¤. (ì˜ˆ: `["dynamite", "dynemite", "dymamite"]`).

4. ë©”íƒ€ ë°ì´í„°:
- `main.start_dt`: ë°ì´í„°ê°€ í™œì„±í™”ë˜ê¸° ì‹œì‘í•œ ë‚ ì§œì…ë‹ˆë‹¤. (ì˜ˆ: `"2024-12-01"`).
- `main.end_dt`: ë°ì´í„°ê°€ ë¹„í™œì„±í™”ë˜ê±°ë‚˜ ë§Œë£Œë˜ëŠ” ë‚ ì§œì…ë‹ˆë‹¤. (ì˜ˆ: `"2025-01-01"`).
- `main.reg_dt`: ë°ì´í„°ê°€ ì²˜ìŒ ë“±ë¡ëœ ë‚ ì§œì…ë‹ˆë‹¤. (ì˜ˆ: `"2024-11-01"`).

----------------------------------------------------

**Link Addition**:
Whenever a song or artist is mentioned in the response, include a link to the song ID in the following format:  
`(https://genie.co.kr/detail/songInfo?xgnm=`song_id`).

----------------------------------------------------

**History Usage in `analyze_data`**:
When `analyze_data` is called:
1. Check the history using `search_history` to see if the query has been answered before.
2. If found, return the saved response.
3. If not found, perform a new computation or analysis, then save the query and response using `save_to_history`.

----------------------------------------------------

Example session:
Question: ì„±ì‹œê²½ì˜ ë…¸ë˜ "ê±°ë¦¬ì—ì„œ"ì— ëŒ€í•´ ì•Œë ¤ì¤˜.
Thought: ì„±ì‹œê²½ê³¼ ê·¸ì˜ ë…¸ë˜ "ê±°ë¦¬ì—ì„œ"ì— ëŒ€í•´ ê²€ìƒ‰í•´ë´ì•¼ê² ì–´.
Action: multi_web_search_with_date: ë‹¤ë¹„ì¹˜ ìµœê·¼ ë°©ì†¡
PAUSE

Observation: 
search_api: ì„±ì‹œê²½ì€ ëŒ€í•œë¯¼êµ­ì˜ ë°œë¼ë“œ ê°€ìˆ˜ë¡œ, "ê±°ë¦¬ì—ì„œ"ëŠ” ì´ë³„ì˜ ìŠ¬í””ì„ ë‹¤ë£¬ ê·¸ì˜ ëŒ€í‘œê³¡ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
Google: ë‹¤ë¹„ì¹˜ê°€ ìµœê·¼ 'ìœ í¬ì—´ì˜ ìŠ¤ì¼€ì¹˜ë¶'ì—ì„œ 'ê·¸ëŒ€ëŠ” ë‚˜ì˜ ë´„ì´ë‹¤'ë¥¼ ê³µì—°í–ˆìŠµë‹ˆë‹¤ (2024-12-01).
YouTube: ë‹¤ë¹„ì¹˜ê°€ ì§€ë‚œì£¼ ì—…ë¡œë“œëœ ë°©ì†¡ì—ì„œ 'ì‚¬ë‘í•´ì„œ ê·¸ë˜'ë¥¼ ë¼ì´ë¸Œë¡œ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤ (2024-11-30).
Naver: ë‹¤ë¹„ì¹˜ê°€ 'ìŒì•…ì¤‘ì‹¬'ì—ì„œ 'ì‹œê°„ì„ ë©ˆì¶°ë¼'ë¥¼ ë¶ˆë €ìŠµë‹ˆë‹¤ (2024-12-02).

Action: 
save_to_history: { "query": "ì„±ì‹œê²½ - ê±°ë¦¬ì—ì„œ", "response": "ì„±ì‹œê²½ì€ ëŒ€í•œë¯¼êµ­ì˜ ë°œë¼ë“œ ê°€ìˆ˜ë¡œ, 'ê±°ë¦¬ì—ì„œ'ëŠ” ì´ë³„ì˜ ìŠ¬í””ì„ ë‹¤ë£¬ ê·¸ì˜ ëŒ€í‘œê³¡ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤." }

Answer: 
ë‹¤ë¹„ì¹˜ëŠ” ëŒ€í•œë¯¼êµ­ì˜ ë°œë¼ë“œ ê°€ìˆ˜ë¡œ, "ê·¸ëŒ€ëŠ” ë‚˜ì˜ ë´„ì´ë‹¤"ëŠ” ì‚¬ë‘ì„ ë‹¤ë£¬ ë‹¤ë¹„ì¹˜ì˜ ëŒ€í‘œê³¡ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
ë‹¤ë¹„ì¹˜ëŠ” ìµœê·¼ ë‹¤ì–‘í•œ ë°©ì†¡ì—ì„œ ë‹¤ìŒ ê³¡ë“¤ì„ ì„ ë³´ì˜€ìŠµë‹ˆë‹¤:
1. ìœ í¬ì—´ì˜ ìŠ¤ì¼€ì¹˜ë¶: 'ê·¸ëŒ€ëŠ” ë‚˜ì˜ ë´„ì´ë‹¤' (2024-12-01)
2. ìœ íŠœë¸Œ ë¼ì´ë¸Œ: 'ì‚¬ë‘í•´ì„œ ê·¸ë˜' (2024-11-30)
3. ìŒì•…ì¤‘ì‹¬: 'ì‹œê°„ì„ ë©ˆì¶°ë¼' (2024-12-02)

(https://genie.co.kr/detail/songInfo?xgnm=43212134)
""".strip()

# chat_bot = ChatBot(system=bot_prompt)

def query(question, max_turns=3):
    i = 0
    bot = ChatBot(bot_prompt)
    next_prompt = question
    while i < max_turns:
        i += 1
        result = bot(next_prompt)
        actions = [action_re.match(a) for a in result.split('\n') if action_re.match(a)]
        if actions:
            action, action_input = actions[0].groups()
            if action not in known_actions:
                raise Exception(f"Unknown action: {action}: {action_input}")
            st.text(" -- running {} {}".format(action, action_input))
            observation = known_actions[action](action_input)
            st.text("Observation:", observation)
            next_prompt = f"Observation: {observation}"
        else:
            return result
        
# ë©”ì‹œì§€ ì…ë ¥ ì²˜ë¦¬
def on_input_change():

    if not openai_api_key.strip():
        st.warning("OpenAI API keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    user_input = st.session_state.user_input

    if user_input.strip():
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
        st.session_state.past.append(user_input)
        st.session_state.messages.append({"role": "user", "content": user_input})

        # OpenAI API í˜¸ì¶œ
        if openai_api_key.strip():
            try:
                # client = OpenAI(api_key=openai_api_key)
                # response = client.chat.completions.create(
                #     model="gpt-3.5-turbo",
                #     messages=st.session_state.messages
                # )
                # msg = response.choices[0].message.content
                msg = query(user_input)

                # ì‘ë‹µ ë©”ì‹œì§€ ì €ì¥
                # st.session_state.generated.append(msg)
                # st.session_state.messages.append({"role": "assistant", "content": msg})

            except Exception as e:
                msg = "ì°¾ì€ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
                st.error(f"OpenAI API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            st.session_state.generated.append(msg or "No response available.")
        else:
            st.warning("Please enter a valid OpenAI API key.")
            
# # ë©”ì‹œì§€ ì…ë ¥ ì²˜ë¦¬
# def process_message():
#     user_input = st.session_state.user_input
#     if not openai_api_key:
#         st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
#         return
    
#     if user_input.strip():
#         # ì‚¬ìš©ì ì…ë ¥ì„ ChatBotì— ì „ë‹¬
#         result = chat_bot(user_input)

#         # ì•¡ì…˜ ì²˜ë¦¬
#         actions = [action_re.match(a) for a in result.split('\n') if action_re.match(a)]
#         if actions:
#             action, action_input = actions[0].groups()
#             if action in known_actions:
#                 observation = known_actions[action](action_input)
#                 result += f"\nObservation: {observation}"
#             else:
#                 result += f"\nUnknown action: {action}"

#         # ë©”ì‹œì§€ ì €ì¥
#         st.session_state.messages.append({"role": "user", "content": user_input})
#         st.session_state.messages.append({"role": "assistant", "content": result})

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
if st.session_state.messages:
    for message in st.session_state.messages:
        role = message["role"]
        content = message["content"]
        if role == "assistant":
            st.markdown(f"<div style='text-align: left; background-color: #FFD700; padding: 10px; border-radius: 15px;'>{content}</div>", unsafe_allow_html=True)
        # else:
            # st.markdown(f"<div style='text-align: right; background-color: #D3D3D3; padding: 10px; border-radius: 15px;'>{content}</div>", unsafe_allow_html=True)

# ë©”ì‹œì§€ ì´ˆê¸°í™”
def on_btn_click():
    st.session_state.past.clear()
    st.session_state.generated.clear()
    st.session_state.messages = [{"role": "assistant", "content": "Genie ğŸ¤– : ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]

# ì±„íŒ… UI
chat_placeholder = st.empty()
with chat_placeholder.container():
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for i in range(len(st.session_state["past"])):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶œë ¥
        st.markdown(
            f'<div class="chat-bubble user-message">{st.session_state["past"][i]}</div>',
            unsafe_allow_html=True
        )
        # AI ì‘ë‹µ ë©”ì‹œì§€ ì¶œë ¥
        st.markdown(
            f'<div class="chat-bubble ai-message">{st.session_state["generated"][i]}</div>',
            unsafe_allow_html=True
        )
        st.write("")
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown(
    """
    <hr style="border: 1px solid white; margin: 20px 0;">
    """,
    unsafe_allow_html=True
)

# ì´ˆê¸°í™” ë²„íŠ¼
st.button("ëŒ€í™” ì‚­ì œ", on_click=on_btn_click)

# ì‚¬ìš©ì ì…ë ¥ í•„ë“œ
st.text_input("ë©”ì„¸ì§€:", on_change=on_input_change, key="user_input")